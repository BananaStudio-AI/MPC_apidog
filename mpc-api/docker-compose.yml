version: '3.8'

services:
  mpc-api:
    build:
      context: .
      dockerfile: Dockerfile
    restart: always
    ports:
      - "3000:3000"
    environment:
      NODE_ENV: production
      PORT: 3000
      LOG_LEVEL: ${LOG_LEVEL:-info}
      
      # LiteLLM Gateway
      LITELLM_BASE_URL: ${LITELLM_BASE_URL:-http://litellm:4000}
      LITELLM_API_KEY: ${LITELLM_API_KEY:-}
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY:-sk-1234}
      
      # Model Provider Keys (optional, used if calling providers directly)
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
      
    networks:
      - ai-infra-net
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    depends_on:
      - litellm

  # Reference to LiteLLM service (should be started separately)
  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    restart: always
    environment:
      LITELLM_MASTER_KEY: ${LITELLM_MASTER_KEY:-sk-1234}
      OPENAI_API_KEY: ${OPENAI_API_KEY:-}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY:-}
    command: >
      --config /app/config.yaml
      --port 4000
    volumes:
      - ../litellm_config.yaml:/app/config.yaml:ro
    networks:
      - ai-infra-net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  ai-infra-net:
    external: true
