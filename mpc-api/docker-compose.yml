version: '3.8'

services:
  mpc-api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: mpc-api
    ports:
      - "3000:3000"
    environment:
      - PORT=3000
      - LITELLM_BASE_URL=http://litellm:4000
      - LITELLM_API_KEY=${LITELLM_API_KEY}
      - NODE_ENV=production
    networks:
      - ai-infra-net
    restart: unless-stopped
    depends_on:
      - litellm
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost:3000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  litellm:
    image: ghcr.io/berriai/litellm:main-latest
    container_name: litellm
    ports:
      - "4000:4000"
    volumes:
      - ../ai-infra/litellm/config.yaml:/app/config.yaml
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
      - LITELLM_MASTER_KEY=${LITELLM_MASTER_KEY}
    command: ["--config", "/app/config.yaml", "--port", "4000"]
    networks:
      - ai-infra-net
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  ai-infra-net:
    name: ai-infra-net
    external: true
